# connections/consumers.py
import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.db.models import F
from .models import Project, RawElement, QuantityClassificationTag
import asyncio

# --- ë°ì´í„° ì§ë ¬í™” í—¬í¼ í•¨ìˆ˜ë“¤ ---
def serialize_tags(tags):
    return [{'id': str(tag.id), 'name': tag.name} for tag in tags]

@database_sync_to_async
def get_total_element_count(project_id):
    try:
        return RawElement.objects.filter(project_id=project_id).count()
    except Project.DoesNotExist:
        return 0

@database_sync_to_async
def get_serialized_element_chunk(project_id, offset, limit):
    try:
        element_chunk_values = list(
            RawElement.objects.filter(project_id=project_id)
            .order_by('id')
            .values('id', 'project_id', 'element_unique_id', 'updated_at', 'raw_data')[offset:offset + limit]
        )
        if not element_chunk_values: return []
        element_ids_in_chunk = [el['id'] for el in element_chunk_values]
        tags_qs = (
            RawElement.classification_tags.through.objects
            .filter(rawelement_id__in=element_ids_in_chunk)
            .values('rawelement_id')
            .annotate(tag_name=F('quantityclassificationtag__name'))
            .values('rawelement_id', 'tag_name')
        )
        tags_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['rawelement_id']
            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_data['tag_name'])
        for element_data in element_chunk_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        return element_chunk_values
    except Exception as e:
        print(f"Error getting optimized chunk: {e}")
        return []

@database_sync_to_async
def serialize_specific_elements(element_ids):
    try:
        elements_values = list(
            RawElement.objects.filter(id__in=element_ids)
            .values('id', 'project_id', 'element_unique_id', 'updated_at', 'raw_data')
        )
        if not elements_values: return []
        tags_qs = (
            RawElement.classification_tags.through.objects
            .filter(rawelement_id__in=element_ids)
            .values('rawelement_id')
            .annotate(tag_name=F('quantityclassificationtag__name'))
            .values('rawelement_id', 'tag_name')
        )
        tags_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['rawelement_id']
            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_data['tag_name'])
        for element_data in elements_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        return elements_values
    except Exception as e:
        print(f"Error serializing specific elements: {e}")
        return []

class RevitConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.all_incoming_uids = set()
        self.project_id_for_fetch = None
        path = self.scope['path']
        if 'revit-connector' in path:
            self.group_name = 'revit_broadcast_group'
        elif 'blender-connector' in path:
            self.group_name = 'blender_broadcast_group'
        else:
            self.group_name = None
        
        if self.group_name:
            print(f"âœ… [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_add(self.group_name, self.channel_name)
        await self.accept()

    async def disconnect(self, close_code):
        if hasattr(self, 'group_name') and self.group_name:
            print(f"âŒ [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì—ì„œ ë‚˜ê°‘ë‹ˆë‹¤.")
            await self.channel_layer.group_discard(self.group_name, self.channel_name)

    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"\nâœ‰ï¸  [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : type='{msg_type}'")

        if msg_type == 'revit_selection_response':
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name, 
                {'type': 'broadcast_selection', 'unique_ids': payload}
            )
        elif msg_type == 'fetch_progress_start':
            print("[DEBUG] 'fetch_progress_start' ìˆ˜ì‹ . ë™ê¸°í™” ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            self.all_incoming_uids.clear()
            
            # â–¼â–¼â–¼ [ìˆ˜ì •] payloadì—ì„œ project_idë¥¼ ê°€ì ¸ì˜¤ëŠ” ëŒ€ì‹ , ì´ë¯¸ ì €ì¥ëœ ê°’ì„ í™•ì¸í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            print(f"  - í˜„ì¬ ì„¸ì…˜ì˜ í”„ë¡œì íŠ¸ ID: {self.project_id_for_fetch}")
            if not self.project_id_for_fetch:
                print("[CRITICAL ERROR] 'fetch_progress_start' ì‹œì ì— í”„ë¡œì íŠ¸ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ë™ê¸°í™”ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²

            print(f"  - ì „ì²´ ê°ì²´ ìˆ˜: {payload.get('total_elements')}")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        elif msg_type == 'fetch_progress_update':
            print(f"[DEBUG] 'fetch_progress_update' ìˆ˜ì‹ . ì²˜ë¦¬ëœ ê°ì²´: {payload.get('processed_count')}")
            
            # â–¼â–¼â–¼ [ìˆ˜ì •] payloadì˜ project_id ëŒ€ì‹  selfì— ì €ì¥ëœ project_idë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            project_id = self.project_id_for_fetch
            # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²
            
            elements_data = [json.loads(s) for s in payload.get('elements', [])]
            
            chunk_uids = {item['UniqueId'] for item in elements_data if item and 'UniqueId' in item}
            self.all_incoming_uids.update(chunk_uids)
            print(f"  - ì´ë²ˆ ì²­í¬ì˜ UniqueId {len(chunk_uids)}ê°œ ì¶”ê°€. í˜„ì¬ê¹Œì§€ ì´ {len(self.all_incoming_uids)}ê°œ ìˆ˜ì‹ .")

            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
            if project_id and elements_data:
                await asyncio.shield(self.sync_chunk_of_elements(project_id, elements_data))
        
        elif msg_type == 'fetch_progress_complete':
            print("[DEBUG] 'fetch_progress_complete' ìˆ˜ì‹ . ë™ê¸°í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ê³  ì‚­ì œ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            if self.project_id_for_fetch:
                await self.cleanup_old_elements(self.project_id_for_fetch, self.all_incoming_uids)
            else:
                print("[WARNING] 'project_id_for_fetch'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‚­ì œ ì‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        else:
            print(f"[WARNING] ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ ìœ í˜•ì…ë‹ˆë‹¤: {msg_type}")

    async def send_command(self, event):
        command_data = event['command_data']
        
        # â–¼â–¼â–¼ [ì¶”ê°€] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ëª…ë ¹ì¼ ê²½ìš°, project_idë¥¼ ë¯¸ë¦¬ ì €ì¥í•©ë‹ˆë‹¤. â–¼â–¼â–¼
        if command_data.get('command') == 'fetch_all_elements_chunked':
            project_id = command_data.get('project_id')
            self.project_id_for_fetch = project_id
            print(f"ğŸš€ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì„¸ì…˜ ì‹œì‘. Project ID '{project_id}'ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.")
        # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²
        
        print(f"â¡ï¸  [{self.__class__.__name__}] '{self.group_name}' ê·¸ë£¹ì˜ í´ë¼ì´ì–¸íŠ¸ë¡œ ëª…ë ¹ì„ ë³´ëƒ…ë‹ˆë‹¤: {command_data.get('command')}")
        await self.send(text_data=json.dumps(command_data))

    @database_sync_to_async
    def sync_chunk_of_elements(self, project_id, parsed_data):
        print(f"  [DB Sync] ì²­í¬ ë™ê¸°í™” ì‹œì‘: {len(parsed_data)}ê°œ ê°ì²´")
        try:
            project = Project.objects.get(id=project_id)
            uids_in_chunk = [item['UniqueId'] for item in parsed_data if item and 'UniqueId' in item]
            existing_elements_map = {el.element_unique_id: el for el in project.raw_elements.filter(element_unique_id__in=uids_in_chunk)}
            
            to_update, to_create = [], []
            for item in parsed_data:
                if not item or 'UniqueId' not in item: continue
                uid = item['UniqueId']
                if uid in existing_elements_map:
                    elem = existing_elements_map[uid]
                    elem.raw_data = item
                    to_update.append(elem)
                else:
                    to_create.append(RawElement(project=project, element_unique_id=uid, raw_data=item))
            
            if to_update: 
                RawElement.objects.bulk_update(to_update, ['raw_data'])
                print(f"    - {len(to_update)}ê°œ ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
            if to_create: 
                RawElement.objects.bulk_create(to_create, ignore_conflicts=True)
                print(f"    - {len(to_create)}ê°œ ê°ì²´ ìƒˆë¡œ ìƒì„± ì™„ë£Œ.")

        except Exception as e:
            print(f"[ERROR] sync_chunk_of_elements DB ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    @database_sync_to_async
    def cleanup_old_elements(self, project_id, incoming_uids):
        print(f"  [DB Cleanup] ì‚­ì œ ì‘ì—… ì‹œì‘ (Project ID: {project_id})")
        try:
            project = Project.objects.get(id=project_id)
            
            db_uids_qs = project.raw_elements.values_list('element_unique_id', flat=True)
            db_uids = set(db_uids_qs)
            print(f"    - í˜„ì¬ DBì— ì¡´ì¬í•˜ëŠ” UniqueId ìˆ˜: {len(db_uids)}")

            incoming_uids_set = set(incoming_uids)
            print(f"    - ì´ë²ˆ ë™ê¸°í™”ì—ì„œ ë°›ì€ UniqueId ìˆ˜: {len(incoming_uids_set)}")

            to_delete_uids = db_uids - incoming_uids_set
            print(f"    - ì‚­ì œ ëŒ€ìƒ UniqueId ìˆ˜: {len(to_delete_uids)}")
            
            if to_delete_uids:
                print(f"    - ì‚­ì œ ëŒ€ìƒ ID (ìµœëŒ€ 10ê°œ í‘œì‹œ): {list(to_delete_uids)[:10]}")
                deleted_count, _ = project.raw_elements.filter(element_unique_id__in=to_delete_uids).delete()
                print(f"    - DBì—ì„œ {deleted_count}ê°œì˜ ì˜¤ë˜ëœ RawElement ê°ì²´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
            else:
                print("    - ì‚­ì œí•  ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")

        except Exception as e:
            print(f"[ERROR] cleanup_old_elements DB ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

class FrontendConsumer(AsyncWebsocketConsumer):
    frontend_group_name = 'frontend_group'
    async def connect(self): await self.channel_layer.group_add(self.frontend_group_name, self.channel_name); await self.accept()
    async def disconnect(self, close_code): await self.channel_layer.group_discard(self.frontend_group_name, self.channel_name)
    
 
    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"âœ‰ï¸ [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì €ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : type='{msg_type}'")

        if msg_type == 'command_to_client':
            target_group = payload.pop('target_group', 'revit_broadcast_group')
            print(f"   â¡ï¸  '{target_group}' ê·¸ë£¹ìœ¼ë¡œ ëª…ë ¹ì„ ì „ë‹¬í•©ë‹ˆë‹¤: {payload}")
            await self.channel_layer.group_send(target_group, {'type': 'send.command', 'command_data': payload})
        
        # â–¼â–¼â–¼ [ìˆ˜ì •] get_all_elements ë©”ì‹œì§€ ì²˜ë¦¬ ë¶€ë¶„ì— printë¬¸ ì¶”ê°€ â–¼â–¼â–¼
        elif msg_type == 'get_all_elements':
            project_id = payload.get('project_id')
            if project_id:
                print(f"\n[DEBUG] í”„ë¡ íŠ¸ì—”ë“œë¡œë¶€í„° '{project_id}' í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ê°ì²´ ë°ì´í„° ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                total_elements = await get_total_element_count(project_id)
                print(f"[DEBUG] ì´ {total_elements}ê°œì˜ ê°ì²´ë¥¼ ì „ì†¡ ì‹œì‘í•©ë‹ˆë‹¤.")
                await self.send(text_data=json.dumps({'type': 'revit_data_start', 'payload': {'total': total_elements}}))
                
                CHUNK_SIZE = 1000
                for offset in range(0, total_elements, CHUNK_SIZE):
                    chunk = await get_serialized_element_chunk(project_id, offset, CHUNK_SIZE)
                    if chunk:
                        await self.send(text_data=json.dumps({'type': 'revit_data_chunk', 'payload': chunk}))
                    await asyncio.sleep(0.01) # ë¶€í•˜ ë¶„ì‚°ì„ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°
                
                print(f"[DEBUG] {total_elements}ê°œ ê°ì²´ ì „ì†¡ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
                await self.send(text_data=json.dumps({'type': 'revit_data_complete'}))
        # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²
        
        elif msg_type == 'get_tags':
            project_id = payload.get('project_id')
            if project_id:
                tags = await self.db_get_tags(project_id)
                await self.send_tags_update(tags)
        
        elif msg_type in ['create_tag', 'update_tag']:
            project_id = payload.get('project_id')
            if not project_id: return
            if msg_type == 'create_tag': await self.db_create_tag(project_id, payload.get('name'))
            elif msg_type == 'update_tag': await self.db_update_tag(payload.get('tag_id'), payload.get('new_name'))
            
            # ìƒì„± ë˜ëŠ” ìˆ˜ì • í›„ì—ëŠ” íƒœê·¸ ëª©ë¡ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            tags = await self.db_get_tags(project_id)
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

        elif msg_type == 'delete_tag':
            project_id = payload.get('project_id')
            tag_id = payload.get('tag_id')
            if not all([project_id, tag_id]): return

            # 1. íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³ , ì˜í–¥ì„ ë°›ì•˜ë˜ elementë“¤ì˜ ID ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            affected_ids = await self.db_delete_tag(tag_id)

            # 2. ë³€ê²½ëœ ì „ì²´ íƒœê·¸ ëª©ë¡ì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            tags = await self.db_get_tags(project_id)
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

            # 3. ë§Œì•½ ì˜í–¥ì„ ë°›ì€ elementê°€ ìˆì—ˆë‹¤ë©´, í•´ë‹¹ elementë“¤ì˜ ìµœì‹  ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            if affected_ids:
                elements = await serialize_specific_elements(affected_ids)
                await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})            
        elif msg_type in ['assign_tags', 'clear_tags']:
            element_ids = payload.get('element_ids')
            if msg_type == 'assign_tags': await self.db_assign_tags(payload.get('tag_id'), element_ids)
            elif msg_type == 'clear_tags': await self.db_clear_tags(element_ids)
            elements = await serialize_specific_elements(element_ids)
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
    async def broadcast_progress(self, event): await self.send(text_data=json.dumps(event['data']))
    async def broadcast_tags(self, event): await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': event['tags']}))
    async def broadcast_elements(self, event): await self.send(text_data=json.dumps({'type': 'elements_updated', 'elements': event['elements']}))
    async def broadcast_selection(self, event): await self.send(text_data=json.dumps({'type': 'revit_selection_update', 'unique_ids': event['unique_ids']}))
    async def send_tags_update(self, tags): await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': tags}))

    @database_sync_to_async
    def db_get_tags(self, project_id):
        project = Project.objects.get(id=project_id)
        return serialize_tags(project.classification_tags.all())
    @database_sync_to_async
    def db_create_tag(self, project_id, name):
        if not name: return
        project = Project.objects.get(id=project_id)
        QuantityClassificationTag.objects.get_or_create(project=project, name=name)
    @database_sync_to_async
    def db_update_tag(self, tag_id, new_name):
        if not new_name: return
        tag = QuantityClassificationTag.objects.get(id=tag_id)
        tag.name = new_name; tag.save()
    @database_sync_to_async
    def db_delete_tag(self, tag_id):
        """
        íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³ , í•´ë‹¹ íƒœê·¸ì— ì˜í–¥ì„ ë°›ì•˜ë˜ RawElementì˜ ID ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        try:
            # ì‚­ì œí•˜ê¸° ì „ì—, ì–´ë–¤ ê°ì²´ë“¤ì´ ì´ íƒœê·¸ë¥¼ ê°€ì§€ê³  ìˆì—ˆëŠ”ì§€ IDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            tag_to_delete = QuantityClassificationTag.objects.prefetch_related('raw_elements').get(id=tag_id)
            affected_element_ids = list(tag_to_delete.raw_elements.values_list('id', flat=True))
            
            # íƒœê·¸ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. (ManyToManyField ê´€ê³„ëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤)
            tag_to_delete.delete()
            
            return affected_element_ids
        except QuantityClassificationTag.DoesNotExist:
            return [] # ì‚­ì œí•  íƒœê·¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    @database_sync_to_async
    def db_assign_tags(self, tag_id, element_ids):
        tag = QuantityClassificationTag.objects.get(id=tag_id)
        elements_to_update = RawElement.objects.filter(id__in=element_ids)
        for element in elements_to_update:
            element.classification_tags.add(tag)
    @database_sync_to_async
    def db_clear_tags(self, element_ids):
        elements_to_update = RawElement.objects.filter(id__in=element_ids)
        for element in elements_to_update:
            element.classification_tags.clear()